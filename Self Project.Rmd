
```{r}
rm(list = ls())

#Loading all the necessary libraries

library(ggplot2)
library(ggpubr)
library(ggcorrplot)
library(corrplot)
library(leaps)
library(caret)
library(MASS)
library(tree)
library(randomForest)
library(pROC)
library(e1071)
set.seed(seed=987)
```

```{r}
#Data content
df=read.csv("heart.csv")
head(df)
str(df)
```

```{r}
#Re-naming the first column as age
colnames(df)[1] = "age"
head(df)
dim(df)
```

```{r}
#Obtaining a summary of the data and also checking for null values if any
summary(df)
sum(is.na(df))
#no null values
```

```{r}
# Data Categorization 
df$sex <- ifelse(df$sex == 1,'male', 'female')
df$target <- ifelse(df$target == 1, 'present', 'absent')
df$fbs <- ifelse(df$fbs == 1, ">120 mg/dl", "<=120 mg/dl")
df$exang <- ifelse(df$exang == 1, "yes" ,"no")
df$cp <- ifelse(df$cp == 0, "typical angina",ifelse(df$cp == 1, "atypical angina", ifelse(df$cp == 2, "non-anginal pain", "asymptomatic")))
df$restecg <- ifelse(df$restecg == 0, "normal",ifelse(df$restecg == 1, "abnormality", "probable or definite"))
df$slope <- ifelse(df$slope == 0, "upsloping",ifelse(df$slope ==1, "flat value", "downsloping"))
```

```{r}
#Since the dummy variables are numbers or characters we convert them to factors
for(i in 1 : ncol(df)){
  if(length(names(table(df[,i]))) <= 5){
    df[,i] <- as.factor(df[,i])
  }
}
str(df)
```

```{r}
#Exploratory Data Analysis
```

```{r}
#Bar plot for Target 
ggplot(df , aes(x = target,fill = target)) + geom_bar() + xlab("Heart Disease") + ylab("Count") + ggtitle("Presence and Absence of Heart Disease") + scale_fill_discrete(name = "Heart Disease" , labels = c("Absent","Present")) + theme_bw()
```

```{r}
#Box plot comparing age and sex with respect to target
ggplot(df, aes(x = sex, y = age, fill = target)) + geom_boxplot() + scale_fill_discrete(name = "Heart Disease", labels = c("Absent","Present")) + scale_x_discrete(labels = c("0" = "Female","1" = "Male")) + ggtitle("Sex vs Age with respect to presence or absence of Heart Disease") + theme_bw()
```

```{r}
#Plot showing Chest pain of different types with target
ggplot(df , aes(cp , fill = target)) + geom_bar(position = "fill") + xlab("chest pain") + scale_x_discrete(labels = c("0" = "typical angina" , "1" = "atypical angina","2" = "non-anginal pain" , "3" = "asymptomatic")) +ylab("percentage") + ggtitle("Chest pain with presence of absence of heart disease") + scale_fill_discrete(name = "Heart Disease" , labels = c("Absent" , "Present")) + theme_bw()
```

```{r}
# Boxplots comparing BP for different kinds of chest pain for male and female
cp.labs = c("typical angina","atypical angina","non-anginal pain","asymptomatic")
names(cp.labs) = c("typical angina","atypical angina","non-anginal pain","asymptomatic")
ggplot(df, aes(x = sex,y = trestbps)) + geom_boxplot(fill = "darkorange") + xlab("Gender") + ylab("BP") + facet_grid(~cp, labeller = labeller(cp = cp.labs)) + ggtitle("Boxplots showing how BP varies with different kinds of cp for male & female") + theme_bw()
```

```{r}
p0 <- ggplot(df,aes(x=target))+facet_grid(~sex)+geom_bar(fill="forestgreen") + theme_bw()
p1 <- ggplot(df,aes(x=target))+facet_grid(~cp)+geom_bar(fill="hotpink") + theme_bw()
p2 <- ggplot(df,aes(x=target))+facet_grid(~fbs)+geom_bar(fill="darkorange") + theme_bw()
p3 <- ggplot(df,aes(x=target))+facet_grid(~restecg)+geom_bar(fill="darkmagenta") + theme_bw()
p4 <- ggplot(df,aes(x=target))+facet_grid(~exang)+geom_bar(fill="midnightblue") + theme_bw()
p5 <- ggplot(df,aes(x=target))+facet_grid(~slope)+geom_bar(fill="seagreen3") + theme_bw()
p6 <- ggplot(df,aes(x=target))+facet_grid(~ca)+geom_bar(fill="darkturquoise") + theme_bw()
p7 <- ggplot(df,aes(x=target))+facet_grid(~thal)+geom_bar(fill="red4") + theme_bw()
ggarrange(p0,p1,p2,p3,p4,p5,p6,p7,nrow=4,ncol=2)
```
```{r}
c=cor(df[,c("age","trestbps","chol","thalach","oldpeak")])
ggcorrplot(corr = c,lab = T)
```

```{r dummy variables}
to_dummy <- data.frame(df$cp,df$restecg,df$slope,df$ca,df$thal)
dmy <- dummyVars(" ~ .", data = to_dummy)
df2 <- data.frame(predict(dmy, newdata = to_dummy))
df2 <- df2[, !(colnames(df2) %in% c("df.cp.typical.angina", "df.restecg.normal","df.slope.flat.value","df.ca.0","df.thal.0"))]
df <- df[,!(colnames(df) %in% c("cp","restecg","slope","ca","thal"))]
df <- cbind(df, df2)
head(df)
dim(df)
```

```{r variable selection}
reg_full <- regsubsets(target~.,data=df,nvmax=23)
s_full<- summary(reg_full)
names(s_full)
which.min(s_full$bic)
plot(s_full$bic,xlab ="No. of Variables",ylab=expression(paste("BIC")),type="l")
points(10,s_full$bic[10],col="red",cex=2,pch=20)

names(coef(reg_full,10))[-1]
```

```{r}
head(df)
colnames(df)
```

```{r}
df_new = df[,-c(1,3,4,5,6,8,13,14,16,20,21,22)]
head(df_new)
```

```{r}
ind1=sample(1:nrow(df_new),floor(0.6*nrow(df_new)))
train=df_new[ind1,]
rem=df_new[-ind1,]
ind2=sample(1:nrow(rem),floor(0.5*nrow(rem)))
cv=rem[ind2,]
test=rem[-ind2,]
obs_target=cv$target
print("The data is successfully split into Train, Test and Cross Validation Set")
```

```{r}
logistic_fit <- glm(target~.,data = train,family="binomial")
logistic_pred <- rep("absent", nrow(cv))
pred_prob <- predict(logistic_fit, newdata = cv, type = "response")
logistic_pred [pred_prob > 0.5] = "present"
temp1 = table(logistic_pred, obs_target)
temp1
paste("Accuracy of the logistic regression model is: ",mean(logistic_pred == obs_target))
```

```{r}
precision1 = temp1[2,2]/(temp1[2,2]+temp1[2,1])
recall1 = temp1[2,2]/(temp1[2,2]+temp1[1,2])
fscore1 = (2*precision1*recall1)/(precision1+recall1)
misclassification.rate.logistic = (mean(logistic_pred != obs_target))*100
paste("Misclassification Error Rate for Logistic Regression is",misclassification.rate.logistic,"%")
paste("The f1 score for Logistic Regression is ",fscore1)
```


```{r}
tree_fit <- tree(target ~., train , method="class")
summary(tree_fit)
plot(tree_fit)
text(tree_fit, pretty=0, cex=1)
tree_pred <- predict(tree_fit, cv, type="class")
temp2 = table(pred_target = tree_pred, obs_target)
temp2
paste("Accuracy of the decision tree classifier model is: ",mean(tree_pred == obs_target))
```

```{r}
precision2 = temp2[2,2]/(temp2[2,2]+temp2[2,1])
recall2 = temp2[2,2]/(temp2[2,2]+temp2[1,2])
fscore2 = (2*precision2*recall2)/(precision2+recall2)
misclassification.rate.tree = (mean(tree_pred != obs_target))*100
paste("Misclassification Error Rate for classification tree is", misclassification.rate.tree, "%")
paste("The f1 score for Classification tree is ",fscore2)
```

```{r}
rf_fit <- randomForest(target ~., data = train)
rf_pred <- predict(rf_fit, cv)
temp3 = table(pred_target = rf_pred, obs_target)
temp3
paste("Accuracy of the decision tree classifier model is: ", mean(rf_pred == obs_target))
```

```{r}
precision3 = temp3[2,2]/(temp3[2,2]+temp3[2,1])
recall3 = temp3[2,2]/(temp3[2,2]+temp3[1,2])
fscore3 = (2*precision3*recall3)/(precision3+recall3)
misclassification.rate.rf = (mean(rf_pred != obs_target))*100
paste("Misclassification Error Rate for random forest is ", misclassification.rate.rf, "%")
paste("The f1 score for random forest is ",fscore3)
```
```{r}
svm_fit <- svm(formula = target ~ .,data = train, type = 'C-classification', kernel = 'linear')
svm_pred = predict(svm_fit, cv)
temp4 = table(pred_target = svm_pred, obs_target)
temp4
paste("Accuracy of the svm classifier model is: ",mean(svm_pred == obs_target))
```

```{r}
precision4 = temp4[2,2]/(temp4[2,2]+temp4[2,1])
recall4 = temp4[2,2]/(temp4[2,2]+temp4[1,2])
fscore4 = (2*precision4*recall4)/(precision4+recall4)
misclassification.rate.svm = (mean(svm_pred != obs_target))*100
paste("Misclassification Error Rate for SVM is", misclassification.rate.svm, "%")
paste("The f1 score for SVM is", fscore4)
```


```{r}
# Since accuracy for Logistic Regression Model has best accuracy on cross validation set and hence we apply this model on the test data
```

```{r}
pred_prob_test <- predict(logistic_fit, newdata = test,type = "response")
logistic_pred_test <- rep("absent",nrow(test))
logistic_pred_test [pred_prob_test > 0.5] = "present"
obs_target_test = test$target
table(logistic_pred_test, obs_target_test)
mean(logistic_pred_test == obs_target_test)
misclassification.test.logistic = mean(logistic_pred_test != obs_target_test)*100
paste("Misclassification Error Rate for final model is",misclassification.test.logistic,"%")
```

```{r}
#Assessing final model accuracy via ROC curve
ROC=roc(obs_target_test,pred_prob_test)
plot(ROC,col="blue",xlab="1-Specificity",ylab= "Sensitivity")
auc(ROC)
```
















